# -*- coding: utf-8 -*-
"""Thuc_Session 5.7_ETL & Logistic Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1oLaZQIHZiTh23pg7nRigEmjU2I_s83H_

# HR Analytics: Job Change of Data Scientists

## **0. Import libary**
"""

import pandas as pd
import numpy as np

"""## **1. Extract Data**

We have various data stored in different sources:

### **1.1. Enrollies' data**

As enrollies are submitting their request to join the course via Google Forms, we have the Google Sheet that stores data about enrolled students, containing the following columns:

- `enrollee_id`: unique ID of an enrollee
- `full_name`: full name of an enrollee
- `city`: the name of an enrollie's city
- `gender`: gender of an enrollee

The source: https://docs.google.com/spreadsheets/d/1VCkHwBjJGRJ21asd9pxW4_0z2PWuKhbLR3gUHm-p4GI/edit?usp=sharing
"""

google_sheet_id = '1VCkHwBjJGRJ21asd9pxW4_0z2PWuKhbLR3gUHm-p4GI'
url = 'https://docs.google.com/spreadsheets/d/' + google_sheet_id + '/export?export=xlsx'
enrollies = pd.read_excel(url, sheet_name='enrollies')

# Check if enrollies data is loaded correctly
enrollies.head()

"""### **1.2. Enrollies' education**
After enrollment everyone should fill the form about their education level. This form is being digitalized manually. Educational department stores it in the Excel format here: https://assets.swisscoding.edu.vn/company_course/enrollies_education.xlsx

This table contains the following columns:

- `enrollee_id`: A unique identifier for each enrollee. This integer value uniquely distinguishes each participant in the dataset.

- `enrolled_university`: Indicates the enrollee's university enrollment status. Possible values include no_enrollment, Part time course, and Full time course.

- `education_level`: Represents the highest level of education attained by the enrollee. Examples include Graduate, Masters, etc.

- `major_discipline`: Specifies the primary field of study for the enrollee. Examples include STEM, Business Degree, etc.
"""

# Download the Excel file
import os
import requests

def download_file(url, filename):
    """
    Download a file from a URL and save it locally.
    """
    response = requests.get(url)
    response.raise_for_status()  # Ensure we notice bad responses
    with open(filename, 'wb') as f:
        f.write(response.content)
    print(f"{filename} downloaded successfully.")

# URLs of the Excel file
excel_url = "https://assets.swisscoding.edu.vn/company_course/enrollies_education.xlsx"

# Output filename
excel_filename = "enrollies_education.xlsx"

# Download the file
download_file(excel_url, excel_filename)

print("Excel file downloaded successfully. Ready for processing!")

enrollies_education = pd.read_excel('/content/enrollies_education.xlsx')

# Check if data is loaded correctly
enrollies_education.head()

"""### **1.3. Enrollies' working experience**
Another survey that is being collected manually by educational department is about working experience.

Educational department stores it in the CSV format here: https://assets.swisscoding.edu.vn/company_course/work_experience.csv

This table contains the following columns:

- `enrollee_id`: A unique identifier for each enrollee. This integer value uniquely distinguishes each participant in the dataset.

- `relevent_experience`: Indicates whether the enrollee has relevant work experience related to the field they are currently studying or working in. Possible values include Has relevent experience and No relevent experience.

- `experience`: Represents the number of years of work experience the enrollee has. This can be a specific number or a range (e.g., >20, <1).

- `company_size`: Specifies the size of the company where the enrollee has worked, based on the number of employees. Examples include 50−99, 100−500, etc.

- `company_type`: Indicates the type of company where the enrollee has worked. Examples include Pvt Ltd, Funded Startup, etc.

- `last_new_job`: Represents the number of years since the enrollee's last job change. Examples include never, >4, 1, etc.
"""

# Dowload the CSV file
import os
import requests

def download_file(url, filename):
    """
    Download a file from a URL and save it locally.
    """
    response = requests.get(url)
    response.raise_for_status()  # Ensure we notice bad responses
    with open(filename, 'wb') as f:
        f.write(response.content)
    print(f"{filename} downloaded successfully.")

# URLs of CSV file
csv_url = "https://assets.swisscoding.edu.vn/company_course/work_experience.csv"

# Output filename
csv_filename = "work_experience.csv"

# Download the file
download_file(csv_url, csv_filename)

print("CSV file downloaded successfully. Ready for processing!")

working_experience = pd.read_csv('/content/work_experience.csv')

# Check if data loaded correctly
working_experience.head()

"""## **1.4. Training hours**

From LMS system's database you can retrieve a number of training hours for each student that they have completed.

**Database credentials:**

- Database type: `MySQL`
- Host: `112.213.86.31`
- Port: `3360`
- Login: `etl_practice`
- Password: `550814`
- Database name: `company_course`
- Table name: `training_hours`
"""

# Make MySQL connector installation
!pip install pymysql

import pymysql
from sqlalchemy import create_engine

engine = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')
training_hours = pd.read_sql_table('training_hours', con=engine)

# Check if data loaded correctly
training_hours.head()

"""## **1.5. City development index**
Another source that can be usefull is the table of City development index.

The City Development Index (CDI) is a measure designed to capture the level of development in cities. It may be significant for the resulting prediction of student's employment motivation.

It is stored here: https://sca-programming-school.github.io/city_development_index/index.html
"""

tables = pd.read_html('https://sca-programming-school.github.io/city_development_index/index.html')

# Read the first table from the webpage as the City Development Index data
cities = tables[0]

# Check if data loaded correctly
cities.head()

"""## **1.6. Employment**
From LMS database you can also retrieve the fact of employment. If student is marked as employed, it means that this student started to work in our company after finishing the course.

Database credentials:

- Database type: `MySQL`
- Host: `112.213.86.31`
- Port: `3360`
- Login: `etl_practice`
- Password: `550814`
- Database name: `company_course`
- Table name: `employment`
"""

engine = create_engine('mysql+pymysql://etl_practice:550814@112.213.86.31:3360/company_course')
employment = pd.read_sql_table('employment', con=engine)

# Check if data loaded correctly
employment.head()

"""## **2. Transform Data**

## **2.1. Enrollies data**
"""

enrollies.info()

"""#### Fixing data types
We need to fix the data types for column `full_name`, `city` and `gender`
"""

enrollies['full_name'] = enrollies['full_name'].astype('string')
enrollies['city'] = enrollies['city'].astype('category')
enrollies['gender'] = enrollies['gender'].astype('category')

# Check again
enrollies.info()

enrollies.sample(10)

"""#### Handling missing data for `gender`"""

gender_mode = enrollies['gender'].mode()[0]
enrollies['gender'] = enrollies['gender'].fillna(gender_mode)

enrollies.info()

"""### **2.2. Enrollies education**"""

enrollies_education.info()

# Consistent data type
enrollies_education['enrolled_university'] = enrollies_education['enrolled_university'].astype('string')
enrollies_education['education_level'] = enrollies_education['education_level'].astype('category')
enrollies_education['major_discipline'] = enrollies_education['major_discipline'].astype('category')

# handling missing
enrollies_education['enrolled_university'] = enrollies_education['enrolled_university'].fillna('missing')
enrollies_education['education_level'] = enrollies_education['education_level'].fillna(enrollies_education['education_level'].mode()[0])
enrollies_education['major_discipline'] = enrollies_education['major_discipline'].fillna(enrollies_education['major_discipline'].mode()[0])

"""### **2.3. Enrollies Working experience**"""

working_experience.info()

"""#### Handing missing data"""

working_experience['experience'] = working_experience['experience'].fillna(working_experience['experience'].mode()[0])

working_experience['company_size'] = working_experience['company_size'].fillna('missing')
working_experience['company_type'] = working_experience['company_type'].fillna('missing')
working_experience['last_new_job'] = working_experience['last_new_job'].fillna('missing')

"""### Fix data types"""

cat_cols = ['relevent_experience', 'experience', 'company_size', 'company_type', 'last_new_job']
working_experience[cat_cols] = working_experience[cat_cols].astype('category')

# Check result
working_experience.info()

"""### **2.4. Training hours**"""

training_hours.info()

"""### **2.5. City Development Index**"""

cities.info()

"""### **2.6. Employment**"""

employment.info()

"""## **3. Load Data**

Because our data source come from remote database, we will load data into SQLite database as a Data Warehouse
"""

# Create a path and database for SQLite
db_path = 'data_warehouse.db'

# Create an SQLAlchemy engine
engine = create_engine(f'sqlite:///{db_path}')

# Load data:
enrollies.to_sql('Enrollies', engine, if_exists='replace', index=False)
enrollies_education.to_sql('Education', engine, if_exists='replace', index=False)
working_experience.to_sql('Working_Experience', engine, if_exists='replace', index=False)
training_hours.to_sql('Training_Hours', engine, if_exists='replace', index=False)
cities.to_sql('Cities', engine, if_exists='replace', index=False)
employment.to_sql('Employment', engine, if_exists='replace', index=False)